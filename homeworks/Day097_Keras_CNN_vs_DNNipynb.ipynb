{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day097_Keras_CNN_vs_DNNipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fmnr80IPA17n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import RMSprop, Adam\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAulQwDRA4lV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "064b42d8-d4e1-4244-bd7d-faa8d17cd3ba"
      },
      "source": [
        "batch_size = 128 # batch 的大小，如果出現 OOM error，請降低這個值\n",
        "num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n",
        "epochs = 10 # 訓練的 epochs 數量\n",
        "\n",
        "# 讀取資料並檢視\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# 對 label 進行 one-hot encoding (y_trian 原本是純數字)\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctx7QleKA6qr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "347696d9-d44a-4f1d-b5d8-6e8a09fb1f82"
      },
      "source": [
        "# 將資料攤平成一維資料\n",
        "x_train = x_train.reshape(50000, 3072) \n",
        "x_test = x_test.reshape(10000, 3072)\n",
        "\n",
        "# 將資料變為 float32 並標準化\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KibxIaGA_j8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        },
        "outputId": "5a990365-7c57-43af-e315-11dddb7ad31e"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(3072,)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,841,162\n",
            "Trainable params: 1,841,162\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "50000/50000 [==============================] - 18s 356us/step - loss: 2.1246 - accuracy: 0.2478 - val_loss: 1.8496 - val_accuracy: 0.3281\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 17s 348us/step - loss: 1.8589 - accuracy: 0.3286 - val_loss: 1.8766 - val_accuracy: 0.3213\n",
            "Epoch 3/10\n",
            "50000/50000 [==============================] - 17s 347us/step - loss: 1.7754 - accuracy: 0.3629 - val_loss: 1.7097 - val_accuracy: 0.3853\n",
            "Epoch 4/10\n",
            "50000/50000 [==============================] - 18s 351us/step - loss: 1.7296 - accuracy: 0.3816 - val_loss: 1.6475 - val_accuracy: 0.4094\n",
            "Epoch 5/10\n",
            "50000/50000 [==============================] - 17s 337us/step - loss: 1.6898 - accuracy: 0.3972 - val_loss: 1.6692 - val_accuracy: 0.4104\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 17s 341us/step - loss: 1.6686 - accuracy: 0.4040 - val_loss: 1.6620 - val_accuracy: 0.4129\n",
            "Epoch 7/10\n",
            "50000/50000 [==============================] - 17s 339us/step - loss: 1.6413 - accuracy: 0.4139 - val_loss: 1.5881 - val_accuracy: 0.4371\n",
            "Epoch 8/10\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 1.6265 - accuracy: 0.4202 - val_loss: 1.6295 - val_accuracy: 0.4299\n",
            "Epoch 9/10\n",
            "50000/50000 [==============================] - 18s 353us/step - loss: 1.6064 - accuracy: 0.4268 - val_loss: 1.6251 - val_accuracy: 0.4223\n",
            "Epoch 10/10\n",
            "50000/50000 [==============================] - 17s 336us/step - loss: 1.6003 - accuracy: 0.4312 - val_loss: 1.5481 - val_accuracy: 0.4513\n",
            "Test loss: 1.5480939678192138\n",
            "Test accuracy: 0.4512999951839447\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6R5AEplBCsk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "7f428a0d-8758-4736-a33c-d39a09920100"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TlPu2i5BGTL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "22947e04-418c-4af8-a383-87e2a6ef3b83"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,250,858\n",
            "Trainable params: 1,250,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "50000/50000 [==============================] - 222s 4ms/step - loss: 1.7163 - accuracy: 0.3802 - val_loss: 1.3712 - val_accuracy: 0.5115\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 223s 4ms/step - loss: 1.2866 - accuracy: 0.5440 - val_loss: 1.1175 - val_accuracy: 0.5975\n",
            "Epoch 3/10\n",
            "50000/50000 [==============================] - 222s 4ms/step - loss: 1.0915 - accuracy: 0.6159 - val_loss: 1.0859 - val_accuracy: 0.6150\n",
            "Epoch 4/10\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.9622 - accuracy: 0.6626 - val_loss: 0.9488 - val_accuracy: 0.6729\n",
            "Epoch 5/10\n",
            "50000/50000 [==============================] - 221s 4ms/step - loss: 0.8734 - accuracy: 0.6959 - val_loss: 0.8208 - val_accuracy: 0.7167\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 219s 4ms/step - loss: 0.8076 - accuracy: 0.7171 - val_loss: 0.7480 - val_accuracy: 0.7412\n",
            "Epoch 7/10\n",
            "50000/50000 [==============================] - 220s 4ms/step - loss: 0.7574 - accuracy: 0.7381 - val_loss: 0.7181 - val_accuracy: 0.7482\n",
            "Epoch 8/10\n",
            "50000/50000 [==============================] - 220s 4ms/step - loss: 0.7162 - accuracy: 0.7501 - val_loss: 0.7201 - val_accuracy: 0.7564\n",
            "Epoch 9/10\n",
            "50000/50000 [==============================] - 220s 4ms/step - loss: 0.6886 - accuracy: 0.7619 - val_loss: 0.7019 - val_accuracy: 0.7672\n",
            "Epoch 10/10\n",
            "50000/50000 [==============================] - 223s 4ms/step - loss: 0.6662 - accuracy: 0.7705 - val_loss: 0.8023 - val_accuracy: 0.7412\n",
            "Test loss: 0.8022771360397339\n",
            "Test accuracy: 0.7411999702453613\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZHCnt7bBS67",
        "colab_type": "text"
      },
      "source": [
        "請試著調整各個超參數，並說明那些超參數對於結果有明顯的影響?\n",
        "ANS: Learing rate, CNN 的 filter的大小\n",
        "\n",
        "\n",
        "CNN 與 DNN 哪個模型的參數數量比較多? 造成參數的數量不同的原因在哪?\n",
        "\n",
        "Ans:DNN的參數量比較多，因為都是DNN,fully conected 所以會明顯多出很多，此外 conv layer 跟 pooling 也會讓 CNN的參數量下降很多。 "
      ]
    }
  ]
}